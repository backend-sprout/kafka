# 안정적인 운영을 위한 주키퍼와 카프카 구성 

안정적으로 카프카를 운영한다는 것은 간단해 보여도 고려해야할 사항이 많다.   
일반적으로 카프카 운영을 단순히 생각할 수도 있는데, 이는 카프카 애플리케이션이 안정적이기 때문이다.  
하지만, **관리자의 소홀로 인해 자칫 큰 장애로 이어질 수도 있으니 방심은 금물이다.**    
   
초기 구성 단계부터 관리자가 꼼꼼하게 **단일 장애 지점등을 제거**하고 클러스터를 구성한다면 안정적으로 운영할 수 있다.  
  
## 주키퍼 구성 

주키퍼는 `파티션`과 `브로커`의 **메타데이터를 저장**하고 컨트롤러 서버를 선출하는 동작을 수행한다.     
  
최근에는 주키퍼의 의존성을 제거하려는 움직임이 있다.    
주키퍼의 역할을 카프카 내부에서 처리함으로써 운영 효율성을 높일 수 있고 효율적인 방식으로 더 많은 파티션을 처리할 수 있다.    
따라서 향후에는 카프카만 설치해 운영할 수 있는 시대가 도래할 것이다.   

### 주키퍼 서버 수량 

주키퍼는 기본적으로 **쿼럼(과반수) 구성을 기반으로 동작하므로 반드시 홀수로 구성해야한다.(최소 3)** 
  
운영 환경에서 카프카의 사용량이 높지 않으며 카프카가 매우 중요한 클러스터가 아니라면 주키퍼는 3대로 구성하는 것을 권장한다.     
반대로, 회사에서 핵심 중앙 데이터 파이프라인으로 카프카를 이용중이고 카프카의 사용량도 높은 경우라면 안정성을 위해 5대를 권장한다.  

### 주키퍼 하드웨어 
  
주키퍼는 높은 하드웨어 리소스를 요구하지 않으므로      
주키퍼의 물리적인 메모리 크기는 `4~8`GB로 구성하고, 디스크는 240G 또는 480G SSD를 사용하는 것을 추천한다.           
주키퍼에서 필요로 하는 힙 메모리 크기는 일반적으로 1~2GB 이며, 나머지는 운영체제 영역 등에서 사용하게 된다.        
주키퍼의 네트워크 카드는 1G 이더넷 카드로 구성하면 된다.(메타 데이터 정도만 주고 받으므로 사용량이 높지 않다)    
    
주키퍼 서버에 과도한 물리 메모리를 장착하는 것은 오히려 메모리를 낭비하는 일이다.      
주키퍼는 트랜잭션이나 스냅샷 로그들을 로컬 디스크에 저장하는 대신,       
일반적인 SAS 디스크 보다는 쓰기 성능이 좋은 SSD를 추천한다.     

### 주키퍼 배치 
  
물리 서버를 배치하는 경우에는 일반적으로 데이터 센터 내에 **랙 마운트**를 하게 된다.      
이때 하나의 랙에 모든 주키퍼 서버를 마운트해 배치하는 것은 매우 위험하다.     

때때로 전원 장애나 네트워크 장애도 발생할 수 있기에 주키퍼를 한곳에 몰아 배치한다면 매우 위험한 상황이 발생할 수 있다.      
따라서 주키퍼를 각기 다른 랙에 분산 배치하는 방안을 권장하며, 이와 동시에 전원 이중화나 스위치 이중화 장치등도 고려해야한다.    
  
최근들어 AWS 같은 퍼블릭 클라우드에서 EC2 인스턴스를 구성해 사용하기도 하는데,     
AWS에서도 분산배치를 위해 가용 영역을 운영하므로 가능한 2개 또는 3개의 가용 영역에 분산해 구성하는 것을 추천한다.     

## 카프카 구성 
  
카프카를 구성할 때 고려해야하는 사항들이 있는데,     
지금부너 설명하는 내용을 잘 고민해 반영한담녀 좀 더 안정적인 카프카 클러스터를 구성할 수 있다.  

### 카프카 서버 수량 

카프카는 주키퍼와 다르게 쿼럼 방식의 구성이 필요하지 않다.       
**즉, 카프카 클러스터의 수가 반드시 홀수일 필요는 없다.**        
  
최소 수량으로 운영한다면 `짝수 2`이지만      
카프카에서 추천하는 안정적인 팩터 수인 3으로 토픽을 구성하기 위해서는 최소 3대의 브로커가 필요하다.      
따라서 카프카를 최소로 구성하기를 원한다면 3대가 적당하다.     

간혹, 트래픽의 발생 가능성에 대비해 처음부터 과도하게 수량을 산정하는 경우도 있는데,   
카프카의 장점 중 하나가 바로 손쉬운 서버 확장이므로 필요할 때 점진적으로 늘리자.  

### 카프카 하드웨어 
 
주키퍼와 달리 카프카의 CPU 사용률은 높은편이다.       
프로듀서나 컨슈머의 처리량을 높이기 위해 배치와 압축 기능을 많이 적용하게 되는데 그에 따른 압축이나 해제에도 많은 리소스가 소모된다.        
그렇다고 해서 최신의 고성능 CPU만 고집할 필요는 없으며 **코어 수가 많은 CPU로 구성할 것을 권장한다.**       
            
메모리는 32GB 부터, 256GB 까지 다양하게 선택할 수 있는데,            
카프카에서 요구하는 JVM 힙 크기는 일반적으로 6GB 정도이므로 이보다 큰 물리 메모리가 필요하다.             
카프카에서는 힙 크기를 제외한 나머지 물리 메모리는 모두 페이지 캐시로 사용해서 빠른 처리를 돕고 있다.     
   
따라서 어느 정도 메모리 여유가 있어야 성능이 도움이 된다.       
128GB, 256GB 등 가용할 수 있는 서버 메모리가 있다면 이 메모리를 그대로 사용하고,      
메모리를 조금 타이트하게 운영하다면 최소 32GB 이상 구성하는 것을 추천한다.    

디스크의 경우 SSD, SAS, SATA, NASA 등 여러 선택지가 있는데 성능이 가장 낮은 SATA를 선택해도 좋다.     
저성능의 SATA 디스크를 사용해도 카프카가 높은 성능을 보장할 수 있는 이유는    
**로그 마지막에 순차적으로 쓰는 방식으로 로그를 기록하기 때문이다.(배치처리 모았다가 씀)**    
     
다만 브로커 한 대에 하나의 물리적 디스크를 사용하는 것이 아니라       
병령 처리를 위해 서버에 약 10개 정도의 디스크를 장착한다.      
간혹, 카프카의 물리적 디스크 크기가 너무 작아 토픽 파티션의 로그가 가득차는 경우가 있는데      
토픽의 보관 주기를 충분하게 설정하려면 4TB 용량 이상의 디스크로 선정하는 것을 추천한다.     
  
NAS 디스크도 하나의 대안이 될 수 있긴 하지만,     
모든 브로커가 하나의 NAS만 바라보고 있다가 NAS가 장애가 발생하다면 이는 매우 큰 문제가 될 수 있으므로     
비용과 안정성 측면을 고려해 NAS는 사용하지 않는 것을 권장한다.     

AWS에서 EC2 인스턴스를 이용해 카프카를 설치 및 운영할 수 있는데, 이때 사용되는 EBS는 안정적이다.      
카프카의 네트워크 카드는 10G 이더넷 카드로 구성하는 것을 추천하며,        
브로커 한 대당 네트워크 사용량 비율이 50%가 넘지 않도록 최대한 토픽을 분산해 운영해야 한다.       

디스크의 장애 복구 또는 신규 브로커 추가로 인해 카프카 클러스터 사이에서는 대량의 데이터 이동이 발생하게 된다.      
이때 많은 트래픽을 사용하게 되므로 네트워크 대역폭은 충분히 확보해둬야한다.    

### 카프카 배치 

주키퍼에서와 마찬가지로, 모든 카프카 서버를 하나의 랙에 마운트하는 것은 매우 위험하다.  

