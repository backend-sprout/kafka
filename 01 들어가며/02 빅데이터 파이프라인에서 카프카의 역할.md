현대의 IT 서비스는 디지털 정보로 기록되는 모든 것을 저장한다.        
기업에서 실시간으로 저장하는 데이터의 양은 최소 테라바이트 단위를 넘어서 엑사바이트를 웃돈다.          
그리고 이러한 데이터들을 우리는 '빅데이터'라고 부른다.      
       
빅데이터로 적재되는 데이터는 `정형 데이터`, `비정형 데이터`들이 있으며         
이러한 수십테라바이트가 넘어가는 데이터들을 `데이터베이스`에 저장하는 것은 거의 불가능하다.           
빅데이터를 저장하고 활용하기 위해서는 일단 생성되는 데이터를 모으는 것이 중요한데 이때 사용되는 것이 **데이터 레이크다.**      
       
**데이터 레이크는 데이터 저장 공간**으로 빅데이터를 관리하고 사용하는 측면에서 중요한 용어(개념)이다.               
데이터 웨어하우스와 다르게 **필터링되거나 패키지화되지 않은 데이터가 저장된다는 점이 특징이다.**                   
즉, 운영되는 서비스로부터 수집 가능한 모든 데이터를 모으는 것이다.         
그리고 데이터 과학자나 데이터 분석가들은 모은 데이터를 토대로 서비스에 활용할 수 있는 인사이트를 찾는다.    
      
**서비스에서 발생하는 데이터를 데이터 레이크로 모으려면 어떻게 해야할까? 🤔**        
단순히 `End To End 방식`으로 넣으면 이전에 언급했던 문제들이 그대로 발생한다.          
이를 해결하기 위해서 **데이터를 `추출`하고 `변경`, `적재`하는 과정을 묶은 `데이터 파이프라인`을 구축해야한다.**          
            
데이터 파이프라인이란, **End to End 방식의 데이터 수집 및 적재를 개선하고 안정성을 추구하며, 유연하면서도 확장 가능하게 자동화한 것이다.**     
안정적이고 확장성이 높은 데이터 파이프라인을 구축하는 것은 빅데이터를 활용하는 기업에게 필수적이다.        
그리고 이러한 데이터 파이프라인을 안정적이고 확장성 높게 운영하기 위한 좋은 방법중 하나가 바로 카프카이다.     
(데이터 파이프라인을 구축하지 않고 일회성으로 구축한 데이터 수집은 결국 데이터 흐름의 파편화로 이어진다.)     
   
## 높은 처리량
              
카프카는 `프로듀서가 브로커로 데이터를 보낼 때`와 `컨슈머가 브로커로부터 데이터를 받을 때` 모두 묶어서 전송한다.              





## 확장성 

## 영속성   
   
## 가용성 





















