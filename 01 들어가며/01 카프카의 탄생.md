# 카프카의 탄생        
     
데이터를 생성하고 적재하기 위해서는             
`데이터를 생성하는 소스 애플리케이션`과 `데이터가 최종 적재되는 타깃 애플리케이션`을 연결해야 한다.          
              
2011년 `링크드인`에서는 파편화된 데이터 수집 및 분배 아키텍처를 운영하는 데에 큰 어려움을 겪었다.                        
초기 운영 시에는 **단방향 통신**을 통해 `소스`에서 `타깃`으로 이동하는 방식을 적용했고 관리가 어렵지 않았다.                     

그러나 시간이 지나면서 아키텍처가 거대해졌고 `소스`, `타깃`의 갯수가 많아지면서 기하급수적으로 복잡해지기 시작해졌다.           
**소스에서 타깃 애플리케이션을 연결하는 파이프라인 개수가 많아지면서 소스 코드 및 버전 관리에서 이슈가 생겼고**                  
**타깃 애플리케이션에 장애가 생길 경우 그 영향이 소스 애플리케이션에 그대로 전달되었다.(직접적 연결이므로)**             
시간이 지날수록 이러한 문제는 더욱이 고도화 될수 밖에 없었고 이를 해결하기 위해 `아파치 카프카`를 개발했다.                             
    
[#](#)   
          
카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 **한 곳에 모아 처리할 수 있도록 중앙 집중화했다.**                   
카프카를 통해 **`웹사이트`, `애플리케이`, `센서` 등에서 취합한 데이터 스트림을 한 곳에서 실시간으로 관리할 수 있게 된 것이다.**            
카프카는 대용량 데이터를 수집하고 이를 **사용자들이 실시간 스트림으로 소비할 수 있게 만들어주는 일종의 중추 신경으로 동작한다고 볼 수 있다.**           

[#](#)         
      
**카프카를 중앙에 배치함으로써 소스 애플리케이션과 타깃 애플리케이션 사이의 의존도를 최소화하여 커플링을 완화하였다.**    
기존에 1:1 매칭으로 개발하고 운영하던 데이터 파이프라인 커플링으로 인해            
한쪽의 이슈가 다른 한쪽의 애플리케이션에 영향을 미치곤 했지만, 카프카는 이러한 의존도를 타파했다.     
더불어 카프카를 이용하면 생성된 데이터를 어느 타깃으로 보낼것인지 고민하지 않아도 된다.       
     
카프카 내부에 데이터를 저장하는 **파티션의 동작은 FIFO 방식**으로 이루어지며         
큐에 데이터를 보내는 것을 `프로듀서`이고, 큐에서 데이터를 가져가는 것을 `컨슈머`라고 한다.        
     
* 프로듀서 : 큐에 데이터를 보내는 것     
* 컨슈머 : 큐에서 데이터를 가져가는 것  

[#](#)  

카프카는 `직렬화`, `역직렬화`, `ByteArray`로 통신하기 때문에 **통신에 사용될 데이터 포맷에는 제한이 없다.**       
특히 자바에서 **선언 가능한 모든 객체를 지원**하며, **카프카 클라이언트에서는 기본적으로 `직렬화/역직렬화` 클래스를 제공해주기도 한다.**   
만약 필요할 경우에는 카프카에서 제공하는 커스텀 직렬화/역직렬화 클래스인 `Serializer<T>`, `DeSerializer<T>`를 상속받으면 된다.   
     

















