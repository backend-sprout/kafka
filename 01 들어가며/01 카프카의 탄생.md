# 카프카의 탄생        
     
데이터를 생성하고 적재하기 위해서는             
`데이터를 생성하는 소스 애플리케이션`과 `데이터가 최종 적재되는 타깃 애플리케이션`을 연결해야 한다.          
              
2011년 `링크드인`에서는 파편화된 데이터 수집 및 분배 아키텍처를 운영하는 데에 큰 어려움을 겪었다.                        
초기 운영 시에는 **단방향 통신**을 통해 `소스`에서 `타깃`으로 이동하는 방식을 적용했고 관리가 어렵지 않았다.                     

그러나 시간이 지나면서 아키텍처가 거대해졌고 `소스`, `타깃`의 갯수가 많아지면서 기하급수적으로 복잡해지기 시작해졌다.           
소스에서 타깃 애플리케이션을 연결하는 파이프라인 개수가 많아지면서 소스 코드 및 버전 관리에서 이슈가 생겼고             
타깃 애플리케이션에 장애가 생길 경우 그 영향이 소스 애플리케이션에 그대로 전달되었다.(직접적 연결이므로)         
시간이 지날수록 이러한 문제는 더욱이 고도화 될수 밖에 없었고 이를 해결하기 위해 `아파치 카프카`를 개발했다.                           
  
[#](#)   
  
카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 중앙집중화했다.             
카프카를 통해 웹사이트, 애플리켕션, 센서 등에서 취합한 데이터 스트림을 한 곳에서 실시간으로 관리할 수 있게 된 것이다.       
카프카는 기업의 대용량 데이터를 수집하고        
이를 사용자들이 실시간 스트림으로 소비할 수 있게 만들어주는 일종의 중추 신경으로 동작한다고 볼 수 있다.        

[#](#)

```
기존에 나와있던 각종 상용 데이터 프레임워크와 오픈소스를 아키텍처에 녹여내어 데이터 파이프라인의 파편화를 개선하려고 했다.       
다양한 메시징 플랫폼과 ERL툴을 적용하여 아키텍처를 변경하려고 노력했지만          
파편화된 데이터 파이프라인의 복잡도를 낮춰주는 아키텍처가 되지는 못했다.       
```













