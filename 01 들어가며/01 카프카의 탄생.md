# 카프카의 탄생        
     
데이터를 생성하고 적재하기 위해서는             
`데이터를 생성하는 소스 애플리케이션`과 `데이터가 최종 적재되는 타깃 애플리케이션`을 연결해야 한다.          
              
2011년 `링크드인`에서는 파편화된 데이터 수집 및 분배 아키텍처를 운영하는 데에 큰 어려움을 겪었다.                        
초기 운영 시에는 **단방향 통신**을 통해 `소스`에서 `타깃`으로 이동하는 방식을 적용했고 관리가 어렵지 않았다.                     

그러나 시간이 지나면서 아키텍처가 거대해졌고 `소스`, `타깃`의 갯수가 많아지면서 기하급수적으로 복잡해지기 시작해졌다.           
소스에서 타깃 애플리케이션을 연결하는 파이프라인 개수가 많아지면서 소스 코드 및 버전 관리에서 이슈가 생겼고             
타깃 애플리케이션에 장애가 생길 경우 그 영향이 소스 애플리케이션에 그대로 전달되었다.(직접적 연결이므로)         
                                   
시간이 지날수록 이러한 문제는 더욱이 고도화 될수 밖에 없었기에 이러한 문제를 해결하기 위해 카프카를 개발했다.        













