# 컨슈머   
프로듀서가 전송한 데이터는 카프카 브로커에 적재된다.     
컨슈머는 적재된 데이터를 사용하기 위해 브로커로부터 데이터를 가져와서 필요한 처리를 한다.    
(토픽으로부터 데이터를 가져와서 문자 발송 처리를 한다.)     
    
## 컨슈머 중요 개념 

토픽의 파티션으로부터 데이터를 가져가기 위해 컨슈머를 운영하는 방법은 크게 2가지이다.  

* 1개 이상의 컨슈머로 이루어진 컨슈머 그룹을 운영한다.     
* 토픽의 특정 파티션만 구독하는 컨슈머를 운영한다.    

## 컨슈머 그룹  

컨슈머를 그룹단위로 격리된 환경에서 안전하게 운영할 수 있도록 하는 방식      
컨슈머 그룹의 컨슈머들은 1개 이상 파티션들에 할당되어 데이터를 가져갈 수 있다.             
      
컨슈머 그룹으로 묶인 컨슈머가 토픽을 구독해서 데이터를 가져갈 때,    
1개의 파티션은 최대 1개의 컨슈머에 할당 가능하고 1개 컨슈머는 여러 개의 파티션에 할당 될 수 있다.      
실은 여러 컨슈머를 둘 수 있지만, 성능상 이점이 아니라 저하(불필요한 스레드 낭비)를 일으키기 때문에 지양한다.      
이러한 특징으로 **컨슈머 그룹의 컨슈머 개수는 가져가고자 하는 토픽의 파티션 개수보다 같거나 적어야한다.**       

컨슈머 그룹은 다른 컨슈머 그룹과 격리되는 특징을 가지고 있다.     
따라서 카프카 프로듀서가 보낸 데이터를 각기 다른 역할을 하는 컨슈머 그룹끼리 영향을 받지 않게 처리할 수 있다.    
  
격리되었을때의 장점을 이해하기 위해 데이터파이프라인을 구축한다고 가정한다.     
1. 리소스 수집
2. 엘라스틱에 저장(시간순으로 확인하기 위해)  
3. 하둡에 저장(대용량 적재를 위해)    

카프카 아닐시, 서버에서 실행되는 리소스 수집 및 전송 에이전트는 수집한 리소스를 엘라스턱 서치와 하둡에 적재하기 위해 동기적으로 요청한다.  
이렇게 동기로 실행되는 에이전트는 엘라스틱서치 또는 하둡 둘중 하나에 장애가 발생한다면 더는 적재가 불가능할 수 있다.      

카프카는 파이프라인 운영시, 장애에 유연한 대을을 위해 각기 다른 저장소마다 컨슈머그룹을 달리하면서 운영할 수 있다.      
즉,장애가 발생하더라도 다른 그룹에 영향을 주지도 받지도 않으며     
장애를 복구하면 오프셋 개념을 통해 적재 완료한 데이터 이후의 데이터부터 다시 읽으면서 가용성을 유지한다.     
     
데이터 파이프로안을 운영함에 있어 적절히 컨슈머 그룹을 분리하여 운영하는 것은 매우 중요하다.    
만약, 동일 컨슈머 그룹으로 작업을 했다면 이전 동기 문제가 동일하게 발생할 수 있다.        
운영하고 있는 토픽의 데이터가 어디에 적재되는지, 어떻게 처리되는지 파악하고 컨슈머 그룹으로 따로 나눌 수 있는 것은 최대한 나누는 것이 좋다.    

## 리밸런싱 

컨슈머에 장애가 발생하면 동일 컨슈머 그룹의 다른 컨슈머에 소유권이 넘어간다.          
이러한 과정을 리밸런싱이라고 부르고, 크게 2가지 상황에서 발생한다.     
   
* 컨슈머가 추가되는 상황   
* 컨슈머가 제외되는 상황   
     
컨슈머에 이슈가 발생하면 매핑된 파티션은 더는 데이터를 처리하지 못하고 있으므로 데이터 처리에 지연이 발생한다.          
리밸런싱을 통해 이슈 발생 컨슈머를 컨슈머 그룹에서 제외하고, 매핑되었던 파티션을 다른 컨슈머와 매핑하여 가용성을 높인다.    
즉, 리밸런싱을 통해 모든 파티션이 지속적으로 데이터를 처리할 수 있도록 가용성을 높여준다.   
    
리밸런싱은 컨슈머가 데이터를 처리하는 도중에 언제든지 발생할 수 있으므로,  데이터 처리 중 발생한 리밸런싱에 대응하는 코드를 작성해야한다.      
  
리밸런싱은 유용하지만 자주 발생하면 안된다.        
리밸런싱이 발생할 때 파티션의 소유권을 컨슈머로 재할당하는 과정에서 해당 컨슈머 그룹의 컨슈머들이 토픽의 데이터를 읽을 수 없기 때문이다.   
(모든 스레드가 멈춘다.)   
  
그룹 조정자는 리밸런싱을 발동시키는 역할을 하는데 컨슈머 그룹의 컨슈머가 추가되고 제거될 때를 감지한다.  
카프카 브로커 중 한대가 그룹 조정자 역할을 수행한다.   

## 커밋과 오프셋 
  
컨슈머는 카프카 브로커로부터 데이터를 어디까지 가져갔는지 **커밋을 통해 기록한다.**       
특정 토픽의 파티션을 어떤 컨슈머 그룹이 몇 번째 가져갔는지     
카프카 브로커내부에서 사용되는 내부 토픽`(__consumer_offsetes)`에 기록된다.       
  
컨슈머 동작 이슈가 발생하여 `(__consumer_offsetes)`토픽에    
어느 레코드까지 읽어갔는지 오프셋 커밋이 기록되지 못했다면 데이터 처리의 중복이 발생할 수 있다.     
그러므로 데이터 처리의 중복이 발생하지 않게 하기 위해서는 컨슈머 애플리케이션이 오프셋 커밋을 정삭적으로 처리했는지 **검증해야한다.**       
         
오프셋 커밋은 컨슈머 애플리케이션에서 명시적, 비명시적으로 수행할 수 있다.              
기본 옵션은 `poll()`가 수행될 때 일정 간격마다 오프셋을 커밋하는 오프셋 커밋을 지원한다.   
  
이 옵션은 `auto.commit.interval.ms` 에 설정된 값과 함께 사용되는데,       
`poll()` 메서드가 `auto.commit.interval.ms`에 설정된 값 이상이 지났을 때 그 시점까지 읽은 레코드의 오프셋을 커밋한다.      
즉, 시간이 지나고 `poll()`를 호출하면 오프셋 커밋을 수행하므로 코드상에서 따로 커밋 관련 코드를 작성할 필요가 없다.       
  
비명시적인 오프셋 커밋은 편리하지만, `poll()`메서드 호출 이후에 리밸런싱 또는 컨슈머 강제종료 발생 시              
컨슈머가 처리하는 데이터가 중복 또는 유실될 수 있는 가능성이 있는 취약한 구조를 가지고 있다.          
**그러므로 데이터 중복이나 유실을 허요하지 않는 서비스라면 자동 커밋을 사용해서는 안된다.**          
     
명시적으로 오프셋을 커밋하려면, `poll()`호출 이후 `commitSync()` 메서드를 호출하면 된다.          
`commitSync()`는 `poll()`를 통해 반환된 레코드의 가장 마지막 오프셋을 기준으로 커밋을 수행한다.         
`commitSync()`는 브로커에 커밋을 요청하고 커밋이 정상적으로 처리되었는지 응답하기 까지 기다리는데 이는 처리량에 영향을 끼친다.    
데이터 처리 시간에 비해 커밋 요청 및 응답 시간이 오래 걸린다면, 동일  시간당 데이터 처리량이 줄어들기 때문이다.    
   
이를 해결하기 위해 `commitAsync()`를 사용하면 커밋 요청을 전송하고 응답이 오기 전까지 데이터 처리를 수행할 수 있다.       
하지만, 비동기 커밋은 커밋 요청이 실패했을 경우 현재 처리 중인 데이터의 순서를 보장하지 않으며 데이터의 중복 처리가 발생할 수 있다.    

[]()

컨슈머의 내부 구조에 대해서 알아보자면,   
컨슈머는 `poll()`를 통해 레코드들을 반환 받지만, `poll()`를 호출하는 시점에 클러스터에서 데이터를 가져오는 것은 아니다.       
컨슈머 애플리케이션을 실행하게 되면, 내부에서 Fetcher 인스턴스가 생성되어 `poll()` 호출하기 전에 미리 레코드들을 내부 큐로 가졍온다.      
이후에 사용자가 명시적으로 `poll()`를 호출하면 컨슈머는 내부 큐에 있는 레코드들을 반환받아 처리를 수행한다.     

## 컨슈머 주요 옵션 
### 필수 
|컨슈머 옵션|설명|
|----------|---|
|bootstrap.servers|프로듀서가 데이터를 전송할 대상 카프카 클로스터에 속한 브로커의 호스트 이름:포트를 1개 작성한다.<br>2개 이상의 브로커 정보를 입력하여 일부 브로커에 이슈가 발생하더라도, 접속하ㅏ는데에 이슈가 없도록 설정가능하다.|
|key.serializer|레코드의 메시지 키를 직렬화하는 클래스를 지정한다.|
|value.serializer|레코드의 메시지 키를 직렬화하는 클래스를 지정한다.|

### 선택 

|컨슈머 옵션|설명|
|--------|---|
|group.id|컨슈머 그룹 아이디를 지정한다.<br>`subscribe()`로 토픽을 구독하여 사용할 때는 이 옵션을 필수로 넣어야 한다.<br>기본값은 null이다.|    
|auto.offset.reset|컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우, 어느 오프셋부터 읽을지 선택하는 옵션이다.<br>이미 컨슈머 오프셋이 있다면 이 옵션값은 무시된다.<br>이 옵션은 latest, earliest, none 중 한개를 선택할 수 있다.<br>latest로 설정하면 가장 높은(가장 최근) 오프셋 부터 읽기 시작한다.<br>earliest로 설정하면 가장 낮은(가장 오래된)오프셋부터 읽기 시작한다.<br>none으로 설정하면 컨슈머 그룹이 커밋한 기록이 있는지 찾아본다<br>만약 커밋 기록이 없으면 오류를 반환하고, 커밋 기록이 있다면 기존 커밋 기록 이후 오프셋부터 읽기 시작한다.<br>기본은 latest|
|enable.auto.commit|자동커밋할지, 수동커밋할지 선택한다<br>기본값은 true다.|
|auto.commit.interval.ms|자동 커밋일 경우, 오프세 커밋 간격을 지정한다.<br>기본값은 5000(5초)다.|   
|max.poll.records|`poll()`를 통해 반환되는 레코드 개수를 지정한다.<br>기본값은 500이다.|   
|session.timeout.ms|컨슈머가 브로커와 연결이 끊기는 최대 시간이다.<br>이 시간 내에 하트비트를 전송하지 않으면 브로커는 컨슈머에 이슈가 발생했다고 가정하고 리밸런싱을 시작한다.<br>보통 하트비트 시간 간격의 3배로 설정한다.<br>기본값은 10000(10초)다.|   
|heartbeat.interval.ms|하트비트를 전송하는 시간 간격이다.<br> 기본값은 3000(3초)다.|   
|max.poll.interval.ms|`poll()`를 호출하는 간격의 최대 시간을 지정한다.<br>`poll()`를 호출한 이후에 데이터를 처리하는 데에 시간이 너무 많이 걸리는 경우<br>비정상으로 판단하고 리밸런싱을 시작한다.<br>기본값은 300000(5분)분이다.|   
|isolation.level|트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용한다.<br>이 옵션은 read_commmitted, read_uncommitted로 설정하면<br>커밋 여부와 관계없이 파티션에 있는 모든 레코드를 읽는다.<br>기본값은 read_uncommited이다.|  

## 실습 
### 실습 코드  

```kt
class SimpleConsumer

fun main() {
    val logger = LoggerFactory.getLogger(SimpleConsumer::class.java)
    val topic_name = "test"
    val boot_servers = "my-kafka:9092"
    val group_id = "test-group"

    val configs = Properties()
    configs[ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG] = boot_servers
    configs[ConsumerConfig.GROUP_ID_CONFIG] = group_id
    configs[ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG] = StringSerializer::class.java.name
    configs[ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG] = StringSerializer::class.java.name

    val consumer = KafkaConsumer<String, String>(configs)
    consumer.subscribe(listOf(topic_name))

    while (true) {
        val records = consumer.poll(Duration.ofSeconds(1))
        for (record in records) {
            logger.info("{}", record)
        }
    }
}
```
```console
bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
--topic test
```

## 리밸런스 리스너를 가진 컨슈머   
컨슈머 그룹에서 컨슈머가 추가 또는 제거되면 파티션을 컨슈머에 재할당하는 과정인 리밸런스가 일어난다.       
`poll()`를 통해 반환 받은 데이터를 모두 처리하기 전에 리밸런스가 발생하면 데이터를 중복 처리할 수 있다.    
`poll()`를 통해 맏은 데이터 중 일부를 처리했으나 커밋하지 않았기 때문이다.    

리밸런스 발생시 데이터를 중복 처리하지 않게 하기위해서는 리밸런스 발생시 처리한 데이터를 기준으로 커밋을 시도해야한다.      
리밸런스 발생을 감지하기 위해 카프카 라이브러리 `ConsumerRebalanceListener` 인터페이스를 지원한다.     

`ConsumerRebalanceListener` 인터페이스로 구현된 클래스는 `onPartitionAssgined()`와 `onPartitionRevoked()`를 구현해야한다.    

* onPartitionAssgined() : 리밸런스가 끝난 뒤에 파티션이 할당 완료되면 호출되는 메서드다.   
* onPartitionRevoked() : 리밸런스가 시작되기 직전에 호출되는 메서드다.  

마지막으로 처리한 레코드를 기준으로 커밋을 하기 위해서는 리밸런스가 시작하기 직전에 커밋을 하면 되므로    
`onPartitionRevoked()`에 구현하여 처리할 수 있다.    

## 파티션 할당 컨슈머  

컨슈머를 운영할 때 `subscribe()`를 사용하여 구독 형태로 사용하는 것 외에도 **직접 파티션을 컨슈머에 명시적으로 할당하여 운영할 수 있다.**   
컨슈머가 어떤 토픽, 파티션을 할당할지 명시적으로 선언하려면 `assign()`를 사용하면 된다.     
`assign()`는 다수의 TopicPartition 인스턴스를 지닌 자바 컬렉션 타입을 파라미터로 받는다.   
   
TopicPartition 클래스는 카프카 라이브러리 내/외부에서 사용되는 토픽, 파티션의 정보를 담는 객체로 사용된다.      
`subscrine()`를 사용할 때와 다르게 직접 컨슈머가 특정 토픽, 특정 파티션에 할당되므로 리밸런싱 하는 과정이 없다.  

## 컨슈머에 할당된 파티션 확인 방법  

컨슈머에 할당된 토픽과 파티션에 대한 정보는 `assignment()`로 확인할 수 있다.         
`assignment()`는 `Set<TopicPartition>` 인스턴스를 반환한다.       
TopicPartition 클래스는 토픽 이름과 파티션 번호가 포함된 객체다.    

```kt
val consumer: KafkaConsumeer<String, String> = KafkaConsumer(configs)
consumer.subscribe(listOf(TOPIC_NAME))
val assignedTopicPartition: Set<TopicPartition> = consumber.assignment()
```

## 컨슈머의 안전한 종료  

컨슈머 애플리케이션은 안전하게 종료되어야 한다.       
정상적으로 종료되지 않은 컨슈머는 세션 타임아웃이 발생할때 까지 컨슈머 그룹에 남게된다.      
이로 인해, 실제로 종료되었지만 더는 동작을 하지 않는 컨슈머가 존재하기 때문에 파티션의 데이터는 소모되지 못하고 컨슈머 랙이 늘어나게 된다.    
  
컨슈머 랙이 늘어나면 데이터 처리 지연이 발생하게 된다.     
컨슈머를 안전하게 종료하기 위해 KafkaConsumer 클래스는 `wakeup()`를 지원한다.        
`wakeup()`를 실행하여 KafkaConsumer 인스턴스를 안전하게 종료할 수 있다.      
`wakeup()`가 실행된 이후 `poll()`이 호출되면 WakeUpEXcepotion이 발생한다.      
WakeUpEXcepotion이 예외를 받은 뒤에는 데이터 처리를 위해 사용한 자원들을 해제하면 된다.  
  
그리고 마지막에는 `close()`를 호출하여        
카프카 클러스터에 컨슈머가 안전하게 종료되었음을 명시적으로 알려주면 종료가 완료되었다고 볼 수 있다.    
`close()`를 호출하면 해당 컨슈머는 더는 동작하지 않는 다는 것을 명시적으로 알려주므로    
컨슈머 그룹에서 이탈되고 나머지 컨슈머들이 파티션을 할당받게 된다.     

```kt
try {
    while(ture) {
        val records: ConsumerRecords<String, String> = consumer.poll(Duration.ofSeconds(1))
        for(record in records) {
            logger.info("{}", record)
        }
    } catch(WakeupException e) {
        logger.warn("Wakeup consumer")
        // 리소스 종료 처리 
    } finally {
        consumer.close()
    }
}
```
`poll()`를 통해 지속적으로 레코드들을 받아 처리하다 `wakeup()`가 호출되면     
`poll()`가 호출될 때 WakeupException 예외가 발생한다.       
예외가 발생하면 catch문이 WakeupException 을 받아서 컨슈머 종료 전에 사용하던 리소스들을 해제할 수 있다.   
   
**하지만, 여기서 `wakeup()`는 보이지 않는데 어디에 선언해야할까? 🤔**       
자바 애플리케이션의 경우 코드 내부에 셧다운 훅(Shutdown hook)을 구현하여 안전한 종료를 명시적으로 구현할 수 있다.     
셧다운 훅이란, 사용자 또는 OS로부터 종료 요청을 받으며 실행하는 스레드를 뜻한다.     

셧다운 훅을 사용하여 `wakeup()`를 호출하는 예제는 아래와 같다.    

```kt
class Test

fun main() {
    Runtime.getRuntime().addShutdownHook(ShutdownThread())
}

class ShutdownThread : Thread() {
    override fun run() {
        consumer.wakeup()
    }
}

```
사용자는 안전한 종료를 위해 위코드로 실행된 애플리케이션에 `kill -TERM`를 호출하여 셧다운 훅을 발생시킬 수 있다.   
셧다운 훅이 발생하면 사용자가 정의한 ShutdownThread 스레드가 실행되면서 `wakeup()`가 호출되어 컨슈머를 안전하게 종료할 수 있다.  

# 어드민 API  

실제 운영호나경에서는 프로듀서와 컨슈머를 통해 데이터를 주고받는 것만큼      
**카프카에 설정된 내부 옵션을 설정하고 확인하는 것이 중요하다.**         

내부 옵션을 확인하는 가장 확실한 방법은 브로커 중 한 대에 접속하여 카프카 브로커 옵션을 확인하는 것이지만 번거롭다.    
카프카 커맨드 라인 인터페이스로 명령을 내려 확인하는 방법도 존재하지만 1회성 작업에 그친다.    

**카프카 클라이언트에서는 내부 옵션들을 설정하거나, 조회하기 위해 AdminClient 클래스를 제공한다.**    
AdminClient 클래스를 활용하면 클러스터의 옵션과 관련된 부분을 자동화할 수 있다.     

* 카프카 컨슈머를 멀티 스레드로 생성할 때, 구독하는 토픽의 파티션 개수만큼 스레드를 생성하고 싶을 때  
  스레드 생성 전에 해당 토픽의 파티션 개수를 어드민 API를 통해 가져올 수 있다.       
* AdminClient 클래스로 구현한 웹 대시버드를 통해 ACL이 적용된 클러스터의 리소스 접근 권한 규칙을 추가할 수 있다.     
* 특정 토픽의 데이터양이 늘어남을 감지하고, AdminClient 클래스로 해당 토픽의 파티션을 늘릴 수 있다.   

```kt
fun main(args: Array<String>) {
    val configs: Properties = Properties()
    configs[ProducerConfig.BOOTSTRAP_SERVERS_CONFIG] = "my-kafka:90902"
    val admin: AdminClient = AdminClient.create(configs)
}
```
프로듀서 API 또는 컨슈머 API와 다르게 추가 설정 없이 클러스터 정보에 대한 설정만 하면 된다.   
`create()`로 KafkaAdminClient를 반환받는다.  
KafkaAdminClient는 브로커의 옵션들을 확인, 설정할 수 있는 유틸 클래스다.   
KafkaAdminClient 에서 제공하는 주요 메서드는 아래와 같다.   

|메서드|설명|
|-----|---|
|`descibeCluster(DescribeClusterOptions options)`|브로커의 정보 조회|
|`listTopics(ListTopicsOptions options)`|토픽 리스트 조회|
|`listConsumerGroups(ListConsumerGroupsOptions options)`|컨슈머 그룹 조회 |
|`createPartitions(Map<String, New Partitions> newPartitions,`<br>`CreatePartitionsOptions options`|파티션 개수 변경|
|`createAcls(Collection<AciBinding> acls, CreateAclsOptions options)`|접근 제어 규칙 생성|


```kt
class AdminClientTest

fun main(args: Array<String>) {
    val configs: Properties = Properties()
    configs[ProducerConfig.BOOTSTRAP_SERVERS_CONFIG] = "my-kafka:90902"
    val admin: AdminClient = AdminClient.create(configs)

    for (node: Node in admin.describeCluster().nodes().get()) {
        val cr: ConfigResource = ConfigResource(ConfigResource.Type.BROKER, node.idString())
        val describeConfigs: DescribeConfigsResult = admin.describeConfigs(Collections.singleton(cr))
        describeConfigs.all().get().forEach { (broker, config) ->
            config.entries().forEach { println(it) }
        }
    }
}
```

## 토픽 정보 조회  

```kt
    val topicInformation: Map<String, TopicDescription> = 
        admin.describeTopics(Collections.singletonList("test")).all().get()
```  
토픽 설정을 조회하는 어드민 API의 결과는 다음과 같으며     
파티션 개수, 파티션의 위치, 리더 파티션의 위치 등을 확인할 수 있다.    

```
실습 후 올림 
```
어드민 API는 사용하고 나면 명시적으로 종료 메서드를 호출하여 리소스가 남ㅇ빋되지 않도록 한다.    
AdminClient 클래스의 `close()` 메서드를 사용하면 명시적으로 종료할 수 있다.   

```kt
admin.close()
```
어드민 API를 활용할 때 클러스터의 버전과 클라이언트의 버전을 맞춰서 사용해야 한다.  
어드민 API의 많은 부분이 버전이 올라가면서 자주 바뀌기 때문이다.   
