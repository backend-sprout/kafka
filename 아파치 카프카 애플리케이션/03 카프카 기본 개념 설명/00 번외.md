# 카프카 스트림즈 

실시간으로 끊임없이 발생하는 데이터를 처리해야할 때 어떤 프레임워크로 처리해야할지 고민이된다.   

* apache hadoop
* apache spark
* apahce strom
* cassandra
* R

여러 프레임워크가 존재하는데, 엄청나게 효과적인 프레임워크가 하나 있는데 바로 ***카프카 스트림즈**다.   
  
카프카는 분산 이벤트 스트리밍 플랫폼으로써 프로듀서와 컨슈머를 통해 데이터를 보내고 가져와서 처리한다.      
카프카 스트림즈는 컨슈머를 사용해서 데이터를 처리하는 것보다 더 안전하고 빠르면서도 다양한 기능을 사용할 수 있는 기술이다.    

카프카 스트림즈는 카프카에서 공식적으로 제공해주는 자바 라이브러리이다.         
토픽에 있는 데이터를 낮은 지연과 함깨 빠른 속도로 데이터를 처리할 수 있다.     
라이버러리 형태로 제공되니까 JVM 기반언어(Java/Kotlin/Scala)에서 사용이 가능하며, 스프링/순수 애플리케이션에서 활용가능하다.     

**장점**
* 카프카와 완벽하게 호환된다.   
    * 대부분의 기업에서는 카프카를 이벤트 저장소로 사용하고 저장된 데이터를 스파크 또는 로그 스태시와 같은 툴로 활용했다.  
    * 하지만, 이런 외부 오픈소스 툴의 문제는 빠르게 발전하는 오픈소스 카프카의 버전에 따라오지 못한다.   
    * 반면, 스트림즈는 카프카가 릴리즈 될때마다 같이 릴리즈되므로 최신 카프카 기능과 완벽호환이 된다.  
    * 카프카의 보안이나 ACL 같은 것들이 붙어있더라도 완벽하게 호환되어 처리될 수 있고 성능 개선도 빠르게 이루어진다.  
    * 그리고 무엇보다도 유실이나 중복 처리되지 않고 딱 한번만 처리될 수 있는 기능을 가진다.(카프카와 연동하는 이벤트 프로세싱 도구중에 거의 유일하다.)    
    * 카프카를 사용하고 있고, 데이터를 안전하고 빠르게 처리하고 싶다면 스트림즈를 1순위로 고려해야한다.    
* 스케줄링 도구가 필요없다.
    * 카프카와 연동하는 스트림 프로세싱 툴로, 가장 많이 널리 사용되는 것은 스파크 스트림이다.   
    * 스파크 스트리밍 또는 스파크 구조적 스트림을 사용하면, 카프카와 연동하여 마이크로 배치처리하는 이벤트 데이터 애플리케이션을 만들 수 있다. 
    * 그런데 문제는 스파크를 운영하기 위해서는 yarn이나 mesos와 같이 클러스터 관리자 또는 리소스 매니저 같은 것들이 필요하다.  
    * 그리고 클러스터를 운영하기 위해 대규모 장비들도 구축해야한다.   
    * 반면에 스트림즈를 사용하면, 스케줄링 도구는 전혀 필요가 없다.  
    * 스트림즈 애플리케이션은 컨슈머 애플리케이션이나 WAS 애플리케이션을 배포하는 것처럼 원하는 만큼 배포하면 된다.  
    * 만약 적은 양의 데이터를 처리해야 한다면 2개 정도의 스트림즈 애플리케이션을 띄워서 운영하면 된다.  
    * 데이터를 많이 처리해야한다면 자연스럽게 스케일 아웃해서 10,20개 애플리케이션을 자연스럽게 배포하면 된다.  
* 스트림즈 DSL과 프로세서 API 제공 
    * 스트림즈를 구현하는 방법은 2가지이다.(스트림즈 DSL과 프로세서 API)    
    * 스트림즈 DSL은 이벤트 기반 데이터 처리를 할때 필요한 다양한 기능을 쩨공한다.(map, join, window)    
    * 프로세서 API는 스트림즈 DSL에서 없는 기능에 대해서 직접 구현하고 사용할 수 있도록 해준다.  
    * 스트림즈 DSL만이 제공하는 KStream, KTable, GlobalKTable 은 그 어디서도 볼 수 없는 독특한 스트림 처리 기능이다.  
    * 카프카를 스트림 데이터 처리뿐만 아니라, 대규모 Key:Value 저장소로도 사용할 수 있는 멋진 기능을 가지고 있다.  
* 자체적으로 로컬 상태저장소를 사용한다.  
    * 실시간으로 들어오는 데이터를 저장하는 방식은 크게 2가지이다.(비상태기반 처리, 상태기반 처리)  
    * Stateless라고 불리는 비상태기반 처리는 필터링이나 데이터를 변환하는 처리이다.  
    * 이런 비상태기반 처리는 데이터가 들어오는 족족이 바로 처리하고 프로듀스하면 되기 때문에 유실이나 중복이 발생할 염려가 적다.  
    * 그런데 문제는 상태 기반 처리는, 상태기반 처리를 직접 구현하려면 window, join, aggregation 과 같은 처리는처리는  
      이전 받았던 데이터를 프로세스가 메모리에 저장하고 있으면서 다음 데이터를 처리해야해서 어렵다.   
    * 이런 상태기반 분산 프로세스를 구현하는 것은 매우 허들이 높다.  
    * 이런 어려움을 극복하게 도와주는 것이 스트림즈다.  
    * 스트림즈는 이런 어려운 처리를 돕기 위해 로컬에 rocksdb를 사용해서 상태를 저장하고  
    * 이 상태에 대한 변환 정보는 카프카의 변경 로그(changelog) 토픽에 저장된다.   
    * 그래서 스트림즈를 사용하면 프로세스에 장애가 발생하더라도 그 상태가 모두 안전하게 저장되기 때문에  
    * 자연스럽게 장애 복구가 될 수 있다.   

```java
KStream<String, String> paymentStream = builder.stream("payment");
KStream<String, String> filteredStream = paymentStream.filter((key, value) -> key.equals("unknown"));
filteredStream.to("unknown-payment");
```
* payment 토픽에 있는 데이터중 Key값이 unknown 인 데이터를 뽑아 unknown-payment 토픽에 보낸다.    
* 컨슈머를 폴링하거나 프로듀서를 어렵게 구현할 필요가 없어졌다.   
* 이렇게 스트림즈 DSL이 제공하는 이벤트 기반 메서드를 사용하면 쉽게 구현할 수 있다.  

# 카프카 커넥트    

카프카 커넥트는, **반복적인 데이터 파이프라인을 효과적으로 `배포`하고 `관리`하는 방법이다.**      
카프카 커넥트는, 카프카에서 데이터 파이프라인을 반복적으로 만들어내고 개발하고 운영할 때 정말 효과적이다.  
    
카프카 커넥트는 카프카에서 공식적으로 제공하는 컴포넌트 중 하나이다.        
공식 컴포넌트 중 하나라는 듯은, 카프카 생태계에서 빠질 수 없는 아주 중요한 플랫폼 중 하나라는 의미이다.     
카프카 클러스터를 상용에서 운용하고 있다면 반드시 도입을 검토해볼만한 아주 중요한 데이터 파이프라인 플랫폼이다.  

카프카 커넥트는 커넥트와 커넥터로 이루어져있다.(이 둘은 완전히 다른 개념이)      
   
* 카프카 커넥트 :    
    * 커넥터를 동작하도록 실행해주는 프로세스   
    * 그래서 파이프라인으로 동작하는 커넥터를 동작하기 위해서 반드시 커넥트를 실행시켜야 한다.    
* 카프카 커넥터 : 실질적으로 데이터를 처리하는 코드가 담긴 jar 패키지     
    * 커넥터는 일련의 템플릿과 같은 특정 동작을 하는 코드 뭉치라고 보면된다.       
    * 커넥터 안에는 파이프라인에 필요한 여러가지 동작들과 설정, 그리고 실행하는 메서드들이 포함되어 있다.     
    * 토픽에서 오라클 DB에 데이터를 저장하고 싶다면, 커넥터에 insert 메서드를 구현하고 커넥터를 실행하는 방식으로 운영해야한다.  
 
**커넥터는 크게 2가지로 이루어져있다.**    
* 싱크 커넥터 
* 소스 커넥터 

**싱크 커넥터(싱크)** 
* 어딘가로 데이터를 싱크한다는 뜻
* 특정 토픽에 있는 데이터를 오라클, MySQL, ES와 같이 특정 저장소에 저장을 하는 역할 
* 즉, 컨슈머와 같은 역할을 한다고 보면 된다.  

**소스 커넥터(소스)**    
* 데이터베이스로부터 데이터를 가져와서 토픽에 넣는 역할, 즉 프로듀서 역할을 하고 있다.  
   
토픽의 데이터를 오라클의 특정 테이블에 넣고 싶다면? 싱크 커넥터를 사용하면 된다.      
보통 싱크 커넥터 글자 앞에 어떤 데이터베이스에 넣을 것인지 선언하는데         
오라클의 테이블에 데이터를 저장하고 싶다면 OracleSinkConnector 로 명명한다.  

## 커넥터를 실행하는 카프카 커넥트 알아보기  

커넥트는 2가지로 이루어진다.  

1. 단일 실행 모드 커넥트 
2. 분산 모드 커넥트 

단일 모드 커넥트는 간단한 데이터 파이프라인을 구성하거나 개발용으로 주로 사용된다.   
실질적으로 상용에 활용하고 싶다면, 분산 모드 커넥트로 구성을 해서 운영을 한다.   

분산 모드 커넥트는 여러 프로세스를 한 개의 클러스로 묶어서 운영하는 방시이다.       
즉, 2개 이상의 카프카 커넥트를 하나의 클러스터로 묶어서 사용하는 방식이다.     
이렇게 클러스터로 묶은 커넥트는 일부 커넥트에 장애가 발생하더라도   
파이프라인을 자연스럽게 failover를 해서 나머지 실행중인 커넥트에서 데이터를 지속적으로 처리할 수 있도록 도와준다.  

## 데이터 파이프라인! 커넥터와 커넥트의 동작 방식은?  

커넥터와 커넥트의 관계는 어떻게 될까?   
커넥트를 실행할 때 커넥터가 어디에 위치하는지, config 파일에 위치를 지정해야한다.   
커넥터 jar 패키지가 있는 디렉토리를 config 파일에 지정하게 된다.    

```
plugin.path=/var/connectors
``` 

그리고 나서 커넥트를 실행하게 되면 이 jar 파일의 커넥터들을 함께 모아서     
커넥터를 실행할 수 있도록 준비상태에 돌입하게 되는 것이다.      
   
실행중인 커넥트에서 커넥터를 실행하려면 우리가 흔히 아는 REST API를 통해서 커넥터를 실행할 수 있다.    
이제 우리는 커넥트를 활용하면, 우리가 파이프라인을 만들 때 추가로 개발을하고 배포하는 과정 없이       
REST API를 통해서 커넥터를 통한 파이프라인들이 분산해서 생기는 것이죠    
 
예를 들어, 오라클 DB에 데이터를 저장하는 OracleSinkConnector가 있는 것을 가정할 수 있는데        
그러면 특정 토픽에 있는 데이터를 특정 테이블로 보낼때, JSON으로 설정을 만들고 이 body를 REST API를 통해 커넥트에 명령을 내린다.      
이 파이프라인을 만들어 달라고 말이다.      
    
그러고 나면 커넥트에 파이프라인이 생성된다.       
만약 동일한 토픽에 대해서 또 다른 테이블에 넣고 싶다고 생각하면       
똑같이 설정 JSON을 만들되, 타겟되는 토픽과 싱크하는 테이블의 이름을 지정하면 된다.       
그리고 나서 REST API를 통해서 또 한번 요청을 하게 되면 파이프라인이 한 개 더 생성이 되는 것이다.   
   
REST API 두번 호출을 통해 순식간에 파이프라인이 2개가 생성된 것이다.       
사실 커넥트를 활용하지 않는다면 이렇게 파이프라인을 반복적으로 만드는데 시간이 엄청나게 많이 걸린다.       
개발하고 배포하고 모니터링을 구축하고 이런 일련의 과정들이       
커넥트에서는 템플릿 형태로 커넥터를 개발하고 REST API를 통해서 반복적으로 생성해서 굉장히 효율이 뛰어나다고 볼 수 있다.      
  
이렇게 파이프라인을 반복적으로 만들 때는       
굳이 컨슈머로 여러번 만들기 보다는 커넥트를 구축해서 반복적으로 커넥터들을 실행하는 방식으로 진행해봐도 좋다.    
  
여기까지 데이터 파이프라인을 효율적으로 반복적으로 배포하고 운영하는 방안에 대해 살펴보앗다.     
카프카 커넥트는 이런 반복 작업에 효과적이다.    
그리고 이런 커넥터 같은 경우에는 직접 구현도 가능하지만, 이미 깃허브나 컨플루언트에 오픈소스로 많이 나와있다.      
그래서 사용하는 카프카 클러스터와 싱크 혹은 소스로 사용하는 데이터베이스가 있다면 커넥터를 찾아서 개발하지 않고도     
오픈 소스 커넥터를 이용해서 파이프라인을 빠르게 구성할 수 있다.      
 
# 카프카 미러메이킹  
