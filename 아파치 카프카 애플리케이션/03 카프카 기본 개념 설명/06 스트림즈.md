# 카프카 스트림즈 
   
카프카 스트림즈는 토픽에 적재된 **데이터를 실시간으로 변환하여 다른 토픽에 적재하는 라이브러리이다.**      
카프카의 스트림 데이터 처리를 위한 다양한 오픈소스가 존재하지만 **카프카 스트림즈를 사용해야하는 이유는 무엇일까?🤔**       
   
**자바 호환**     
스트림즈는 카프카에서 공식적으로 지원하는 라이브러리로 버전이 오를때마다 스트림즈 자바 라이브러리도 같이 릴리즈된다.            
그렇기 때문에 자바 기반 스트림즈 애플리케이션은 카프카 클러스터와 완벽하게 호환되면서         
스트림 처리에 필요한 편리한 기능등 (신규 토픽 생성, 상태 저장, 데이터 조인..)을 지원한다.      
    
**장애 허용 시스템**       
스트림즈 애플리케이션 또는 카프카 브로커의 장애가 발생하더라도          
정확히 한번 할 수 있도록 장애 허용 시스템을 가지고 있어서 데이터 처리 안정성도 매우 뛰어나다.     
    
카프카 클러스터를 운영하면서 실시간 스트림 처리를 해야하는 필요성이 있다면        
카프카 스트림즈 애플리케이션으로 개발하는 것을 1순위로 고려하는 것이 좋다.    
     
## 프로듀서와 컨슈머를 조합해서 사용하지 않고 스트림즈를 사용해야하는 이유   
스트림 데이터 처리에 있어 필요한 다양한 기능을 스트림즈 DSL로 제공하며 프로세서 API를 사용하여 기능을 확장할 수 있다.      
          
컨슈머와 프로듀서를 조합하여 스트림즈가 제공하는 기능과 유사하게 만들 수 있다.        
그러나 단 한번의 데이터 처리, 장애 허용 시스템등의 특징들은 컨슈머와 프로듀서의 조합만으로는 완벽하게 구현하기는 어렵다.      
다만, **스트림즈가 제공하지 못하는 기능을 구현할 때는 컨슈머와 프로듀서를 조합하여 구현하면 좋다.**          
       
예를 들어, 소스 토픽(사용하는 토픽)과 싱크 토픽(저장하는 토픽)의 카프카 클러스터가 서로 다른 경우는      
스트림즈가 지원하지 않으므로 이때는 컨슈머와 프로듀서 조합으로 직접 클러스터를 지정하는 방식으로 개발할 수 있다.       
    

## 
  
보통의 분산 시스템이나 스케줄링 프로그램들은 스트림즈를 운영하는데 불필요하다.     
자바 라이브러리로 구현하는 스트림즈 애플리케이션은 JVM 위에서 하나의 프로세스로 실행되기 때문이다.   

[#](#) 

**스트림즈의 태스크는 스트림즈 애플리케이션을 실행하면 생기는 데이터 처리 최소 단위이다.**    
스트림즈 애플리케이션은 내부적으로 스레드를 1개 이상 생성할 수 있으며, 스레드는 1개 이상의 태스크를 가진다.     
만약 3개의 파티션으로 이루어진 토픽을 처리하는 스트림즈 애플리케이션을 실행하면 내부에 3개의 태스크가 생긴다.    
(컨슈머의 병렬처리를 위해 컨슈머 그룹으로 이루어진 컨슈머 스레드를 여러개 실행하는 것과 비슷하다)   
  
카프카 스트림즈는 컨슈머 스레드를 늘리는 방법과 동일하게      
병렬처리를 위해 파티션과 스트림즈 스레드(또는 프로세스) 개수를 늘림으로써 처리량을 늘릴 수 있다.     

[#](#)   
  
실제 운영환경에서는 장애가 발생하더라도 안정적으로 운영할 수 있도록         
2개 이상의 서버로 구성하여 스트림즈 애플리케이션을 운영한다.       
이를 통해 일부 스트림즈 애플리케이션 또는 애플리케이션이 실행되는 서버에 장애가 발생하더라도 안전하게 스트림 처리를 할 수 있다.   

[#](#)   

토폴로지란 2개 이상의 노드들과 선으로 이루어진 집합을 뜻한다.           
토폴로지 종류로는 링형, 트리형, 성형등이 있는데 스트림즈에서 사용하는 토폴로지는 트리 형태와 유사하다.   

* 프로세서 : 토폴로지를 이루는 하나의 노드 
* 스트림 : 노드와 노드를 이은 선  
  
[#](#)  
  
**프로세서의 종류**
* 소스 프로세서 : 
    * 데이터를 처리하기 위해 최초로 선언하는 노드
    * 하나 이상의 토픽에서 데이터를 가져오는 역할을 한다.  
* 스트림 프로세서 : 
    * 다른 프로세서가 반환한 데이터를 처리하는 역할을 한다. 
    * 변환 분기처리와 같은 로직이 데이터 처리의 일종이라 볼 수 있다.   
* 싱크 프로세서 : 
    * 데이터를 특정 카프카 토픽으로 저장하는 역할을 한다.
    * 스트림즈로 처리된 데이터의 최종 종착지이다.   


카프카 스트림즈는 스트림즈DSL 과 프로세서 API 2가지 방법으로 개발 가능하다.    

스트림즈 DSL은 스트림 프로레싱에 쓰일 만한 기능들을 자체 API로 만들었기에 대부분의 변환 로직을 쉽게 개발할 수 있다.      
만약, 스트림즈 DSL에서 제공지 않는 일부 기능들의 경우에는 프로세서 API를 사용하여 구현할 수 있다.   

**스트림즈 DSL로 구현하는 데이터 처리 예시**  
* 메시지 값을 기반으로 토픽 분기처리      
* 지난 10분간 들어온 데이터의 개수 집계     
* 토픽과 다른 토픽의 결합으로 새로운 데이터 생성 

**프로세서 API로 구현하는 데이터 처리 예시**
* 메시지 값의 종류에 따라 토픽을 가변적으로 전송  
* 일정한 시간 간격으로 데이터 처리    

## 스트림즈 DSL  

스트림즈 DSL 에서 다루는 새로운 개념들을 짚고 넘어가자       
스트림즈 DSL 에는 레코드의 흐름을 추상화한 3가지 개념이 있다.     
이 3가지 개념은 컨슈머, 프로듀서, 프레세서 API에서는 사용되지 않고 스트림즈 DSL에서만 사용되는 개념이다.  
  
**스트림즈 DSL 레코드 흐름 추상화 3개념**  
* KStream
* KTable
* GlobalKTable 

### KStream 

[#](#)
  
KStream은 레코드의 흐름을 표현한 것으로 `메시지 키`와 `메시지 값`으로 구성되어있다.           
KStream으로 데이터를 조회하면 토픽에 존재하는 모든 레코드가 출력된다.         
KStream은 컨슈머로 토픽을 구독하는 것과 동일한 선상에서 사용하는 것이라고 볼 수 있다.      

### KTable  
 
[#](#)  
  
KTable은 KStream과 다르게 메시지 키를 기준으로 묶어서 사용한다.   
     
KStream은 토픽의 모든 레코드를 조회할 수 있지만,        
KTable은 유니크한 메시지 키를 기준으로 가장 최신 레코드를 사용한다.      
**그러므로 데이터를 조회하면 메시지 키를 기준으로 가장 최신에 추가된 레코드의 데이터가 출력된다.**         
새로 데이터를 적재할 때 동일한 메시지 키가 있을 경우 데이터가 업데이트되었다고 볼 수 있다.(최신 갱신)     

### GlobalKTable 

  
GlobalKTable은 KTable과 동일하게 메시지 키를 기준으로 묶어서 사용된다.       
KTable로 선언된 토픽은 1개 파티션이 1개의 태스크에 할당되어 사용되고,     
GlobalKTable로 선언된 토픽은 모든 파티션 데이터가 각 태스크에 할당되어 사용한다는 차이가 있다.   

[#](#)  

GlobalKTable은 KStream과 KTable이 데이터 조인을 수행할때 예시를 들 수 있다.      
KStream과 KTable을 조인하려면 반드시 코파티셔닝(co-partitioning)되어 있어야한다.      
 
코파티셔닝이란, 조인을 하는 2개의 데이터의 파티션 갯수가 동일하고 파티셔닝 전략을 동일하게 맞추는 작업이다.    
파티션 개수가 동일하고 파티셔닝 전력이 같은 경우에는 동일한 메시지 키를 가진 데이터가 동일한 태스크에 들어가는 것을 보장한다.    
이를 통해 각 태스크는 KStream의 레코드와 KTable의 메시지키가 동일할 경우 조인을 수행할 수 있다.    

[#](#)  
  
문제는 조인을 수행하려는 토픽들이 코파티셔닝되어 있음을 보장할 수 없다는 것이다.       
KStream과 KTable로 사용하는 2개의 토픽이 파티션 개수가 다를 수 있고, 파티션 전략이 다를 수 있다.      
이런 경우 조인이 불가능하며, 조인 로직이 담긴 스트림즈 애플리케이션을 실행하면 TopologyException이 발생한다.   

[#](#)  

코파티셔닝되어 있지 않으면 KStream 또는 KTable을 리파티션닝해야한다.    
리파티셔닝이란 새로운 토픽에 새로운ㅇ 메시지 키를 가지도록 재배열하는 과정이다.     
리파티셔닝 과정을 거쳐 KStream 토픽과 KTable로 사용하는 토픽이 코파티셔닝되도록 할 수 있다.   
  
그런데 코파티셔닝이 되어 있지 않은 2개의 토픽을 조인하기 위해 항상 리파티셔닝 과정을 거쳐야할까?     
리파티셔닝을 하는 과정은 토픽에 기존 데이터를 중복해서 생성할 뿐만 아니라 파티션을 재배열하기 위해 프로세싱하는 과정도 거쳐야한다.  















