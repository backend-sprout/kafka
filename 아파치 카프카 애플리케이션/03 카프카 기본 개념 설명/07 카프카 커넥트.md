# 카프카 커넥트 
## 카프카 커넥트란?  
  
카프카 커넥트는 카프카 오픈소스에 포함된 툴 중 하나로        
**데이터 파이프라인 생성시 반복 작업을 줄이고 효울적인 전송을 이루기 위한 애플리케이션이다.**         

파이프 라인을 생성할 때 `프로듀서`, `컨슈머` 애플리케이션을 만드는 것은 좋은 방법이지만   
반복적인 파이프라인 생성 작업이 있을 때는 매번 `프로듀서`, `컨슈머` 애플리케이션을 개발하고 배포, 운영해야하기 때문에 비효율적이다.    
 
커넥트는 특정한 작엽 형태를 **템플릿으로 만들어놓은 커넥터를 실행**함으로써 반복 작업을 줄일 수 있다.     
파이프라인 생성 시 자주 반복되는 값들(토픽 이름, 파일 이름, 테이블 이름)을 파라미터로 받는 커넥터를 코드로 작성하면     
이후에 파이프라인을 실행할 때는 코드를 작성할 필요가 없기 때문이다.    

커넥터는 **각 커넥터가 가진 고유한 설정 값을 입력받아서 데이터를 처리한다.**  
예를 들어, 파일의 데이터를 토픽으로 보내는 커넥터가 있다면 파일이 존재하는 디렉토리 위치, 파일 이름을 설정해야한다.        

## 카프카 커넥터 종류 
   
커넥터는 2가지로 나뉜다.   
* 소스 커넥터 : 프로듀서 역할    
* 싱크 커넥터 : 컨슈머 역할   

예를 들어, 파일을 주고 받는 용도로 `파일 소스 커넥터`와 `파일 싱크 커넥터`가 있다고 가정한다.     
파일 소스 커넥터는 파일의 데이터를 카프카 토픽으로 전송하는 프로듀서 역할을 한다.       
파일 싱크 커넥터는 토픽의 데이터를 파일로 저장하는 컨슈머 역할을 한다.      
  
파일 외에도 일정한 프로토콜을 가진 소스 애플리케이션이나 싱크 애플리케이션이 있다면    
커넥터를 통해 카프카로 데이터를 보내거나 카프카에서 데이터를 가져올 수 있다.      

MySQL, S3, MongoDB 등과 같은 저장소를 대표적인 싱크 애플리케이션, 소스 애플리케이션이라 볼 수 있다.     
즉, MySQL에서 카프카로 데이터를 보낼 때 그리고 카프카에서 데이터를 MySQL로 저장할 때,      
JDBC 커넥터를 사용하여 파이프라인을 생성할 수 있다.      
 
카프카 2.6에 포함된 커넥트를 실행할 경우,       
클러스터 간 토픽 미러링을 지원하는 미러메이커2 커넥터와 파일 싱크 커넥터, 파일 소스 커넥터를 기본 플럭그인으로 제공한다.         
이외의 추가적인 커넥터를 사용하고 싶다면 플러그인 형태로 커넥터 jar파일을 추가하여 사용할 수 있다.     
커넥터 jar파일에는 커넥터를 구현하는 클래스를 빌드한 클래스 파일이 포함되어 있다.     
커넥터 플로그인을 추가하고 싶다면 직접 커넥터 플러그인을 만들거나 이미 인터넷에 존재하는 커넥터를 가져와서 사용하면 된다.     

오픈 소스 커넥터의 종류는 매우 다양하다.  
HDFS 커넥터, AWS S3 커넥터, JDBC 커넥터, 엘라스틱 서치 커넥터등 100개가 넘는 커넥터들이 이미 공개되어있다.   
필요한 커넥터를 다운받아 사용하면 되지만, 모두 무료로 공개된 것은 아니니 이점을 주의하자.(라이선스 확인 필요)       
오픈 소스 커넥터의 종류는 [컨플루언트 허브](https://www.confluent.io/hub/)에서 검색할 수 있다.      

사용자가 커넥트에 커넥터 생성 명령을 내리면 커넥트는 내부에 커넥터와 태스크를 생성한다.      
커넥터는 태스크들을 관리한다.       
태스크는 커넥터에 종속되는 개념으로 실질적인 데이터 처리를 한다.      
그렇기 때문에 데이터 처리를 정삭적으로 하는지 확인하기 위해서는 각 태스크의 상태를 확인해야한다.    

## 컨버터와 트랜스 폼 
사용자가 커넥터를 사용하여 파이프라인을 생성할 때 컨버터와 트랜스폼 기능을 옵션으로 추가할 수 있다.    
커넥터를 운영할 때 반드시 필요한 설정은 아니지만, 데이터 처리를 더욱 풍성하게 도와주는 역할을 한다.    
  
**컨버터** 
* 데이터 처리를 하기 전에 스키마를 변경하도록 도와준다.**     
* JsonConverter, StringConverter, ByteArrayConverte를 지원하고 필요하다면 커스텀 컨버터를 작성하여 사용할 수 있다.    
   
**트랜스폼**    
* 데이터 처리 시 각 메시지 단위로 데이터를 간단하게 변환하기 위한 용도로 사용된다.      
* 예를 들어, JSON 데이터를 커넥터에서 사용할 때 트랜스폼을 사용하면 특정 키를 삭제하거나 추가할 수 있다.   
* 기본 제공 트랜스폼으로 Cast, Drop, ExtraField가 있다.     

## 커넥트를 실행하는 방법 

커넥트를 실행하는 방법은 크게 2가지가 있다.  

1. 단일 모드 커넥트 
2. 분산 모드 커넥트 
    
단일 모드 커넥트는 단일 애플리케이션으로 실행된다.      
커넥트를 정의하는 파일을 작성하고 해당 파일을 참조하는 단일 모드 커넥트를 실행함으로써 파이프라인을 생성할 수 있다.      
단일 모드 커넥트는 1개 프로세스만 실행되는 점이 특징인데,      
단일 프로세스로 실행되기 때문에 고가용성이 구성되지 않아서 단일 장애점(SPOF)이 될 수 있다.      
그러므로 단일 모드 커넥트 파이프라인은 주로 개발환경이나 중요도가 낮은 파이프라인을 운영할 때 사용한다.   
  
분산 모드 커넥트는 2대 이상의 서버에서 클러스터 형태로 운영함으로써         
단일 모드 커넥트 대비 안전하게 운영할 수 있다는 장점이 있다.            
2개 이상의 커넥트가 클러스터로 묶이면 이슈 발생으로 중단되더라도 남은 커넥트가 파이프라인을 지속적으로 처리할 수 있다.     
분산 모드 커넥트는 데이터 처리량의 변화에도 유연하게 대응할 수 있다.      
커넥트가 실행되는 서버 개수를 늘림으로써 무중단으로 스케일 아웃하여 처리량을 늘릴 수 있기 때문이다.       
이러한 장점이 있기 때문에 상용환경에서 커넥트를 운영한다면 분산 모드 커넥트를 2대 이상으로 구성하고 설정하는 것이 좋다.  

[#](#)

REST API를 사용하면 현재 실행중인 커넥트의 커넥터 플러그인 종류, 태스크 상태, 커넥터 상태 등을 조회할 수 있다.   
커넥트는 8083 포트로 호출할 수 있으며, HTTP 메서드(GET/POST/DELETE/PUT) 기반 API를 제공한다.   

|요청 메서드|호출 경로|설명| 
|--------|-------|---|  
|GET|`/`|실행 중인 커넥트 정보 확인| 
|GET|`/connectors`|실행 중인 커넥터 이름 확인| 
|POST|`/connectors`|새로운 커넥터 생성 요청| 
|GET|`/connectors/{커넥터 이름}`|실행 중인 커넥터 정보 확인| 
|GET|`/connectors/{커넥터 이름}/config`|실행 중인 커넥터 설정값 확인| 
|PUT|`/connectors/{커넥터 이름}/config`|실행 중인 커넥트 설정값 변경 요청| 
|GET|`/connectors/{커넥터 이름}/status`|실행 중인 커넥터 상태 확인| 
|POST|`/connectors/{커넥터 이름}/restart`|실행 중인 커넥터 재시작 요청| 
|PUT|`/connectors/{커넥터 이름}/pause`|커넥터 일시 중지 요청| 
|PUT|`/connectors/{커넥터 이름}/resume`|일시 중지된 커넥터 실행 요청| 
|DELETE|`/connectors/{커넥터 이름}`|실행중인 커넥터 종료| 
|GET|`/connectors/{커넥터 이름}/tasks`|실행 중인 커넥터의 태스크 정보 확인| 
|GET|`/connectors/{커넥터 이름}/tasks/{태스크 아이디}/status`|실행 중인 커넥터의 태스크 상태 확인| 
|POST|`/connectors/{커넥터 이름}/tasks/{태스크 아이디}/restart`|실행 중인 커넥터의 태스크 재시작 요청|   
|GET|`/connectors/{커넥터 이름}/topics`|커넥터별 연동된 토픽 정보 확인| 
|GET|`/connector-plugins`|커넥트에 존재하는 커넥터 플러그인 확인| 
|PUT|`/connector-plugins/{커넥터 플러그인 이름}/config/validate`|커넥터 생성 시 설정값 유효 여부 확인|   


### 단일 모드 커넥트
  
단일 모드 커넥트를 실행하기 위해서는 단일 모드 커넥트를 참조하는 설정 파일을 수정해야한다.         
설정 파일은 카프카 바이너리 디렉토리의 config 디렉토리에 있는 `connect-standalone.properties` 이다.     
  
**connect-standalone.properties-원본**   
```properties
bootstrap.servers=localhost:9092

key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=true
value.converter.schemas.enable=true

offset.storage.file.filename=/tmp/connect.offsets
offset.flush.interval.ms=10000
```
위와 같은 원본 properties를 아래와 같이 바꿔준다.   


**connect-standalone.properties-변경**   
```properties
bootstrap.servers=my-kafka:9092

key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false

offset.storage.file.filename=/tmp/connect.offsets
offset.flush.interval.ms=10000

plugin.path=/usr/local/share/java,/usr/local/share/kafka/plugins
```
* 커넥트와 연동할 카프카 클러스터의 호스트와 포트를 적어야하기에, my-kafka:9092로 변경했다.   
    * 2개 이상의 브로커로 이루어진 클러스터와 연동할 때는 2개 이상의 정보를 콤마(,)로 구분해서 넣으면 된다.   
* 스키마 형태를 사용하지 않을 예정이라 false로 변경했다.  
* 오프셋 저장 정보 위치와 커밋 주기는 바꾸지 않았다.  
* 플러그인 형태로 추가할 커넥터의 디렉토리의 주소를 입력했다.  
    * 오픈소스로 다운받거나, 직접 개발한 커넥터의 jar파일이 위치하는 디렉토리를 입력하면 된다.    
    * 2개 이상의 플러그인의 경우 디렉토리를 콤마로 구분하여 입력할 수 있다.       
    * 커넥터 이외에도 컨버터, 트랜스폼도 플러그인으로 추가할 수 있다.      

**단일 모드 커넥트는 커넥트 설정파일과 함께 커넥터 설정 파일도 함께 정의하여 실행해야한다.**     
커넥터 설정파일에 대해 알아보기 위해 예시로, 카프카에서 기본으로 제공하는 파일 소스 커넥터를 살펴보자.

**파일 소스 커넥터**   
* 특정 위치에 있는 파일을 읽어서 토픽으로 데이터를 저장하는데 사용하는 커넥터   
* 파일 소스 커넥터 설정파일은 카프카 바이너리가 설치된 디렉토리의 config 디렉토리에 있다.  
* connect-file-source.properties 

**connect-file-source.properties**   
```properties
name=local-file-source               # 커넥터의 이름을 지정(유일해야함)
connector.class=FileStreamSource     # 사용할 커넥터의 클래스 이름을 지정
tasks.max=1                          # 커넥터로 실행할 태스크 개수를 지정한다.(늘려서 병렬처리가능)
file=test.txt                        # 읽을 파일의 위치를 지정한다.    
topic=connect-test                   # 읽은 파일의 데이터를 저장할 토픽의 이름을 지정한다.  
```

설정을 모두 완료했으므로(커넥터는 확인만) 이제 단일 모드 커넥트를 실행할 차례이다.      
단일 모드 커넥트를 실행시에 파라미터 커넥트 설정파일과 커넥터 설정파일을 차례로 넣어 실행하면 된다.   

```console
bin/connect-standalone.sh config/connect-standalone.properties \
config/connect-file-source.properties
```

참고로, 필자의 경우 카프카가 죽었는데 metadata.properties를 삭제해주어야했다.     
[참고](https://stackoverflow.com/questions/59481878/unable-to-start-kafka-with-zookeeper-kafka-common-inconsistentclusteridexceptio)  
  
### 분산 모드 커넥트 

분산 모드 커넥트는 단일 모드 커넥트와 다르게 2개 이상의 프로세스가 1개의 그룹으로 묶여서 운영된다.  
이를 통해 커텍트 프로세스가 종료되더라도 나머지 커넥트 프로세스가 커넥터를 이어받아 파이프라인을 지속적으로 운영할 수 있다.    

분산 모드 커넥트를 묶어서 운영하기 위한 설정파일을 살펴보자     
`config/connect-distributed.properties`

**config/connect-distributed.properties**
```properties
bootstrap.servers=my-kafka:9092 # 여기를 변경했다. 

group.id=connect-cluster

key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false

offset.storage.topic=connect-offsets
offset.storage.replication.factor=1
#offset.storage.partitions=25

config.storage.topic=connect-configs
config.storage.replication.factor=1

status.storage.topic=connect-status
status.storage.replication.factor=1

offset.flush.interval.ms=10000

plugin.path=/usr/local/share/java,/usr/local/share/kafka/plugins
```

분산 커넥트를 실행할 때는 커넥트 설정파일만 있으면 된다.     
커넥터는 커넥트가 실행된 이후에 REST API를 통해 실행/중단/변경할 수 있기 때문이다.    
  
```console
bin/connect-distributed.sh config/connect-distributed.properties
```

테스틑를 위해 분산 모드 커넥트를 프로세스 1개로 실행했지만,      
상용환경에서 운영할 때는 2대 이상의 분리된 서버에서 서버마다 1개의 분산 모드 커넥트를 실행하는 것이 좋다.     

커넥트가 실행되고 난 이후에는 REST API로 커넥트의 상태, 커넥터 생성, 커넥터 조회, 커넥터 수정, 커넥터 중단 등 명령할 수 있다.   
우선, 현재 커넥트에서 사용할 수 있는 플러그인을 조회해보자  

```console
{"class":"org.apache.kafka.connect.file.FileStreamSinkConnector","type":"sink","version":"2.5.0"}, 
{"class":"org.apache.kafka.connect.file.FileStreamSourceConnector","type":"source","version":"2.5.0"},
{"class":"org.apache.kafka.connect.mirror.MirrorCheckpointConnector","type":"source","version":"1"},
{"class":"org.apache.kafka.connect.mirror.MirrorHeartbeatConnector","type":"source","version":"1"}, 
{"class":"org.apache.kafka.connect.mirror.MirrorSourceConnector","type":"source","version":"1"}
```

카프카 2.5 에서는 5가지의 기본 커넥터를 제공하는 것을 알 수 있다.   

```console
curl -X POST -H "Content-Type: application/json" \
--data '{
"name": "local-file-source",
"config":
{
    "connector.class": "org.apache.kafka.connect.file.FileStreamSourceConnector",
"file": "/tmp/test.txt",
"tasks.max": "1",
"topic": "connect-test"
}
}' \
http://localhost:8083/connectors
```
```console
{"name":"local-file-source","config":{"connector.class":"org.apache.kafka.connect.file.FileStreamSourceConnector","file":"/tmp/test.txt","tasks.max":"1","topic":"connect-test","name":"local-file-source"},"tasks":[],"type":"source"}
```

커넥터를 실행하기 위해 설정하는 config 값은 JSON 형태로 body에 데이터를 포함하여 요청해야한다.  
이제 커넥터가 정상적으로 실행되고 있는지 확인해보자  

```console
curl -X GET http://localhost:8083/connectors/local-file-source/status

{"name":"local-file-source","connector":{"state":"RUNNING","worker_id":"192.168.1.42:8083"},"tasks":
[{"id":0,"state":"RUNNING","worker_id":"192.168.1.42:8083"}],"type":"source"}%
```
우선, `/tmp/test.txt`에게 `chmod777`을 주어서 카프카에서 접근 및 변경가능하도록 설정했다.   
커넥트와 태스크 모두 정상적으로 실행되고 있음을 확인할 수 있다.    
커넥터의 사용이 끝나면 커넥터를 종료하여 커넥트가 사용하는 리소스의 낭비를 줄일 수 있다.     
이제 `local-file-source` 커넥터를 종료해보자     

```console
curl -X DELETE http://localhost:8083/connectors/local-file-source
```
커넥터를 종료한 이후에 커넥터 리스트를 확인하여 커넥터가 완전히 중지되었는지 확인할 수 있다.   
  
```console
curl -X GET http://localhost:8083/connectors

[]
```
리턴값으로 JSON의 빈 배열이 출력되었다.    
이뜻은 현재 실행중인 커넥터가 없다는 것이므로 local-file-source 가 종료되었음을 알 수 있다.  

# 실습 
## 소스 커넥터  

소스 커넥터는 소스 애플리케이션 또는 소스 파일로부터 데이터를 가져와 토픽으로 넣는 역할을 한다.       
오픈소스 소스 커넥터를 사용해도 되지만, 라이선스 문제나 로직이 원하는 요구사항과 맞지 않는 경우가 허다하다.    
이러한 경우 직접 개발해야하는데 이때는 카프카 라이브러리에서 제공하는 SourceConnector 와    
SourceTask 클래스를 사용하여 직접 소스 커넥터를 구현하면 된다.  
  
직접 구현한 소스 커넥트를 빌드하여 jar파일로 만들고 커넥트 실행 시 플러그인으로 추가하여 사용할 수 있다.     

**build.gradle**
```gradle
    implementation("org.apache.kafka:connect-api:2.5.0")
```
* 소스 커넥터를 만들기 위해서는 connect-api 라이브러리를 추가해야한다.     
* connect-api 라이브러리는 커넥터 개발에 필요한 클래스들이 다수 포함되어 있다.    

소스 커넥터를 만들때 필요한 클래스는 2개다.  

1. SourceConnector
2. SourceTask
 
SourceConncetor는 태스크를 실행하기 전      
**커넥터 설정 파일을 초기화하고 어떤 태스크 클래스를 사용할 것인지 정의하는 데에 사용한다.**            
그렇기 때문에 Source Connector에는 실질적인 데이터를 다루는 부분이 들어가지는 않는다.     
     
SourceTask가 실제로 데이터를 다루는 클래스라고 볼 수 있다.         
**SourceTask는 소스 애플리케이션 또는 소스 파일로부터 데이터를 가져와서 토픽으로 데이터를 보내는 역할을 수행한다.**          
SourceTask만의 특징은 자체 오프셋을 사용하여, 소스 애플리케이션 또는 소스 파일을 어디까지 읽었는지 저장하는 역할을 한다.   
이 오프셋을 통해 데이터를 중복해서 토픽으로 보내는 것을 방지할 수 있다.   
예를 들어서, 파일의 데이터를 한 줄씩 읽어서 토픽으로 데이터를 보낸다면 토픽으로 데이터를 보낸 줄 번호를 오프셋에 저장할 수 있다.  
예를 들어서, 파일의 데이터를 한 줄씩 읽어서 토픽으로 데이터를 보낸다면 토픽으로 데이터를 보낸 줄 번호를 오프셋에 저장할 수 있다.  

### SourceConnector
SourceConnector를 상속받은 사용자의 클래스를 생성해야한다.   
SourceConnector를 상속받아서 구현한 클래스는 6개의 메서드를 오버라이드하여 내부를 구현해야한다.  

```kt
class TestSourceConnector : SourceConnector() {
    override fun version(): String {
        TODO("Not yet implemented")
    }

    override fun start(props: MutableMap<String, String>?) {
        TODO("Not yet implemented")
    }

    override fun taskClass(): Class<out Task> {
        TODO("Not yet implemented")
    }

    override fun taskConfigs(maxTasks: Int): MutableList<MutableMap<String, String>> {
        TODO("Not yet implemented")
    }

    override fun stop() {
        TODO("Not yet implemented")
    }

    override fun config(): ConfigDef {
        TODO("Not yet implemented")
    }
}
```
* version() : 
    * 커넥터의 버전을 리턴한다.   
    * 커넥트에 포함된 커넥터 플러그인을 조회할 때 이 버전이 노출된다.     
    * 커넥터를 지속적으로 유지보수하고 신규 배포할 때 이 메서드가 리턴하는 버전값을 변경해야한다.   
* start() : 
    * 사용자가 JSON 또는 config 파일 형태로 입력한 설정값을 초기화하는 메서드다.  
    * 만약 올바른 값이 아니라면 여기서 ConnectException() 호출하여 커넥터를 종료할 수 있다.  
        * 예를 들어, JDBC 소스 커텍터라면 JDBC 커넥션 URL 값을 검증하는 로직을 넣을 수 있다.  
        * 만약 비정상적인 URL 값이라면 커넥션을 맺을 필요 없이 커넥터를 종료시킬 수 있다.     
* taskClass() : 
    * 커넥터가 사용할 태스크 클래스를 지정한다.      
* taskConfigs() : 
    * 태스크 개수가 2개 이상인 경우, 태스크마다 각기 다른 옵션을 설정할 때 사용한다.  
* config() :
    * 커넥터가 사용할 설정값에 대한 정보를 받는다.
    * 커넥터의 설정값은 ConfigDef 클래스를 통해 각 설정의 이름, 기본값, 중요도, 설명을 정의할 수 있다.  
* stop() :
    * 커넥터가 종료될 때 필요한 로직을 작성한다.  

### SourceTask
SourceTask를 상속받은 사용자 클래스는 4개의 메서드를 구현해야한다.   
 
```kt
class TestSourceTask: SourceTask() {
    override fun version(): String {
        TODO("Not yet implemented")
    }

    override fun start(props: MutableMap<String, String>?) {
        TODO("Not yet implemented")
    }

    override fun stop() {
        TODO("Not yet implemented")
    }

    override fun poll(): MutableList<SourceRecord> {
        TODO("Not yet implemented")
    }
}
```
* version() : 
    * 태스크의 버전을 지정한다.  
    * 보통 커넥터의 version() 에서 지정한 버전과 동일한 버전으로 작성하는 것이 일반적이다.  
* start() :
    * 태스크가 시작할 때 필요한 로직을 작성한다.  
    * 태스크는 실질적으로 데이터를 처리하는 역할을 하므로 데이터 처리에 필요한 모든 리소스를 여기서 초기화하면 좋다.  
    * 예를 들어, JDBC 소스 커넥터를 구현한다면 이 메서드에서 JDBC 커넥션을 맺는다.    
* poll() :   
    * 소스 애플리케이션 또는 소스 파일로부터 데이터를 읽어오는 로직을 작성한다.      
    * 데이터를 읽어오면 토픽으로 보낼 데이터를 SourceRecord에 정의한다.        
    * SourceRecord 클래스는 토픽으로 데이터를 정의하기 위해 사용한다.      
    * `List<SourceRecord>` 인스턴스에 데이터를 담아 리턴하면 데이터가 토픽으로 전송된다.   
* stop() : 
    * 태스크가 종료될 때 필요한 로직을 작성한다.    
    * JDBC 소스 커넥트를 구현했다면, 이 메서드에서 JDBC 커넥션을 종료하는 로직을 추가하면 된다.     

### 파일 소스 커넥터 구현   

로컬에 지정된 파일을 토픽으로 한줄 씩 읽어서 토픽을 보내는 파일 소스 커넥터를 작성한다.     

```gradle
public class SingleSourceConnectorConfig extends AbstractConfig {

    private static final String DIR_FILE_NAME = "file";
    private static final String DIR_FILE_NAME_DEFAULT_VALUE = "/tmp/kafka.txt";
    private static final String DIR_FILE_NAME_DOC = "읽을 파일 경로와 이름";

    private static final String TOPIC_NAME = "topic";
    private static final String TOPIC_DEFAULT_VALUE = "test";
    private static final String TOPIC_DOC = "보낼 토픽 이름";

    private static final ConfigDef CONFIG = new ConfigDef()
            .define(
                    DIR_FILE_NAME,
                    Type.STRING,
                    DIR_FILE_NAME_DEFAULT_VALUE,
                    Importance.HIGH,
                    DIR_FILE_NAME_DOC)
            .define(
                    TOPIC_NAME,
                    Type.STRING,
                    TOPIC_DEFAULT_VALUE,
                    Importance.HIGH,
                    TOPIC_DOC
            );

    public SingleSourceConnectorConfig(Map<String, String> props) {
        super(CONFIG, props);
    }
}
```
* 파일 소스 커넥터는 어떤 파일을 읽을 것인지 지정해야하므로,   
  파일의 위치와 파일 이름에 대한 정보가 포함되어 있어야 한다.        
  옵션명 file로 파일 위치와 이름을 값으로 받는다.   
* 읽은 파일을 어느 토픽으로 보낼 것인지 지정하기 위해 옵션명을 topic으로 1개의 토픽값을 받는다.    
* ConfigDef는 커넥터에서 사용할 옵션값들에 대한 정의를 표현하는데 사용된다.    
  ConfigDef 클래스는 define() 메서드를 플루언트 스타일로 옵션값으로 지정할 수 있는데,    
  각 옵션값의 이름, 설명, 기본값, 중요도를 지정할 수 있다.    
























